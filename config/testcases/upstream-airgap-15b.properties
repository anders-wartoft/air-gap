# Used in some log events to identify the source
id=Upstream_15b
# Used in the MTU code
nic=lo0
# UDP target (downstream, use static arp and route to be able to send packets over a diode)
targetIP=kafka-downstream.sitia.nu
# UDP target port
targetPort=1234
# Kafka source. If more than one, separate the servers with a comma ,
source=kafka
bootstrapServers=kafka-upstream.sitia.nu:9092,kafka-upstream.sitia.nu:8092
# Topic to read
topic=transfer
# Kafka group id to use. If several threads are used, this is prepended to the thread names.
groupID=15
logLevel=info
# Read from this time instead of starting at the end
#    2024-01-28T10:24:55+01:00
from=
# For testing, you can use random, else use kafka
#source=random
source=kafka
# Downstream public key file
encryption=true
publicKeyFile=certs/server2.pem
# Every n seconds, generate a new symmetric key
generateNewSymmetricKeyEvery=50
#payloadSize=auto
payloadSize=1500
# After reading the config, where should we send the logs? Default is stdout
#logFileName=./tmp/upstream.log
# Format: {"name": "thread_name", "offset": offset_in_seconds}
#sendingThreads=[{"now": 0}, {"3minutes": -10}]
sendingThreads=[{"No-delay": 0}]
# TLS to Kafka
# Certificate file
#certFile=certs/tmp/airgap-upstream.crt
# Key file
#keyFile=certs/tmp/airgap-upstream.key
# CA file
#caFile=certs/tmp/kafka-ca.crt

# To test the gap detection removing gaps, remove the filter out for previously dropped packets
# Deliver every even numbered packet:
#deliverFilter=2,4,6
# compress the payload if events longer than this in bytes
compressWhenLengthExceeds=100
eps=200
